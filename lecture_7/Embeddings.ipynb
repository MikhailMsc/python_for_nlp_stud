{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10013ed2-8be4-48c3-8356-e6471f4c4684",
   "metadata": {},
   "source": [
    "# Векторные модели. Эмбединги.\n",
    "При работе с текстом встает проблема - компьютер понимает числа/вектора, с сырым текстом он работать не умеет?  \n",
    "Поэтому решено было каждому слову/токену сопоставлять какой-то вектор. Желательно чтобы этот вектор был еще каким-то осмысленным, то есть похожие по смыслу слова, должны иметь \"близкие\" вектора.  \n",
    "Существует гипотеза, что значение слова определяется его контекстом — иначе говоря, словами, которые встречаются рядом с этим словом в тексте. \n",
    "И эта гипотеза используется при обучении таких векторов.  \n",
    "За последние десятилетия произошло значительное развитие в представление слов. И сегодня посмотрим на основные шаги в этом процессе."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa83f9a2-1a58-4dce-b859-af0f9f5adc22",
   "metadata": {
    "tags": []
   },
   "source": [
    "# One-Hot Encoding\n",
    "Самый очевидный способ. Мы имеем какой-то словарь и для этого словаря строим матрицу размером `VxV`, где V - размер словаря.\n",
    "Каждая строчка в этой матрице соответствует вектору слова из словаря. Каждый вектор имеет только одну единицу и стоит она на порядковом номере слова.\n",
    "Выглядит это следующим образом:  \n",
    "![](./one-hot_encodding.png)\n",
    "\n",
    "Минусы:\n",
    "- У нас получаются очень большие вектора для слов\n",
    "- Они не несут никакой смысловой нагрузки"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35f4fc6-e960-4d05-8bbf-4cb285d22485",
   "metadata": {},
   "source": [
    "Данные вектора можно использовать для самых простых описаний текстов - Если сложить вектора всех слов в тексте то вы просто получите вектор, в котором подсчитали количество каждого слова. Далее этот вектор можно по разному модернизировать и использовать в моделях. Вы увидите что-то похожее в методах CountVectorizer/TF-IDF."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35934c92-7421-4cfb-b645-f41a3511c459",
   "metadata": {},
   "source": [
    "# Матрица совстречаемости слов. Co-occurence Matrix\n",
    "Создадим матрицу `VxV`, где V - это размер словаря. В ячейках матрицы будем подсчитывать количество совместных встречаний этих слов.\n",
    "Для этого определим размер окна - пусть будет 3 слова. И шагаем с этим окном по тексту, смотрим какие слова в него попадают и повышем соответствующие значения в ячейках матрицы.\n",
    "\n",
    "Как итог получим матрицу такого же размера как и у One-Hot-encoding. Но эта матрица уже имеет намного больше информации.\n",
    "Следующий шаг - сжать эту матрицу до приемлемых размеров. Делается это с помощью [PCA](https://habr.com/ru/post/304214/)\n",
    "\n",
    "\n",
    "Плюсы:\n",
    "- Эта матрица уже хранит семантические отношения между словами, и вектора близких слов будут более похожи, чем далеких.\n",
    "- Быстро учится\n",
    "\n",
    "Минусы:\n",
    "- Что делать с новыми словам? Заново делать матрицу?\n",
    "- Матрица получается очень разреженной, многие слова никогда не встречаются вместе, и это может быть проблемой при SVD разложении"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75b4cd4-0c36-444d-a96f-a15ec430e052",
   "metadata": {},
   "source": [
    "# Word2Vec/W2V (2013г)\n",
    "Однослойная нейросеть которая, обучаясь на корпусе тектов, учится предсказывать либо по контектсту пропущенное слово, либо по слову контекст.\n",
    "Сейчас иногда это уже общее название для совокупности моделей на основе искусственных нейронных сетей, предназначенных для получения векторных представлений слов на естественном языке.   \n",
    "В оригинальной статье предложено две архитектуры:\n",
    "1) CBOW (Continuous Bag-of-Words) — модель предсказывает текущее слово по контексту\n",
    "2) Skip-Gram — модель предсказывает контекст слова\n",
    "\n",
    "Как происходит обучение:\n",
    "- Токенизируете ваш корпус текстов\n",
    "- Составляете ваш словарь основываясь на частоте слов\n",
    "- Формируете выборку для обучения состоящую из примеров:   \n",
    "    (Input:Центральное слово, Output: Слово из контекста) или (Input: Слово из контекста, Output: Центральное слово)\n",
    "\n",
    "Ниже вы показано, что мы считаем контекстом, а что текущим словом:  \n",
    "![word_context.png](./word_context.png)\n",
    "\n",
    "\n",
    "**Здесь сразу виден первый параметр модели** - какой размер контекста нам необходимо выбрать?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06261d0e-3fb0-4d63-9132-227d754bd644",
   "metadata": {},
   "source": [
    "![cbow_skipgram.png](./cbow_skipgram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f4f631-6d9c-4839-bbf1-875637ed670d",
   "metadata": {},
   "source": [
    "**Как понять по векторам что слова близки по смыслу?**\n",
    "Ранее мы говорили что модели эмбединга учатся семантическим связям между словами и близкие по смыслу слова должны иметь похожие вектора.  \n",
    "Для векторов есть такое понятие как - косинусное расстояние. По сути оно показывает на сколько близко ориентированы векторы в пространстве, смотрят ли они в одну сторону. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05494ab-33b0-4434-a60a-b609fdf917d4",
   "metadata": {},
   "source": [
    "Пример:\n",
    "+ король: мужчина = королева: женщина $\\Rightarrow$\n",
    "+ король - мужчина + женщина = королева\n",
    "\n",
    "![w2v](https://cdn-images-1.medium.com/max/2600/1*sXNXYfAqfLUeiDXPCo130w.png)  \n",
    "Ещё про механику с картинками [тут](https://habr.com/ru/post/446530/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810b1517-312c-467b-a40a-58586ce6c5cc",
   "metadata": {},
   "source": [
    "# GloVe: Global Vectors for Word Representation (2014г)\n",
    "Данный метод как раз основывается на матрице совстречаемости слов. Эта матрица из абсолютных значений преобразуется в относительные.\n",
    "И затем строится модель, которой на вход подается два слова, на выходе должны получить значение близкое к значению из относительной матрицы на пересечении этих слов. [Схема описана очень грубо, можно прочитать более подробную информацию здесь.](https://sahiltinky94.medium.com/word-embedding-glove-dd27f630c663)\n",
    "\n",
    "Векторы полученные с помощью GloVe, на мой взляд, имеют лучше качество чем Word2Vec."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76719778-ca1a-4fcd-abd3-e9fe8f54de77",
   "metadata": {},
   "source": [
    "# FastText\n",
    "Самая главная проблема у предыдущих алгоритмов в том что не ясно что делать с неизвестными словами. Они решили этот вопрос просто - создали универсальный токен для всех независимых слов.\n",
    "FastText сделал иначе, он строит эмбединги не только слов но и буквенных нграмм."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4869e0de-5035-4a00-8d8a-645b22eae708",
   "metadata": {},
   "source": [
    "# BERT/GPT/ELMo/etc\n",
    "\n",
    "Это уже более сложные модели, основанные на современных архитектурах нейройнных сетей.  \n",
    "С помощью этих моделей мы получаем не статитчные эмбединги, а учитываем текущий контекст слова, так как само слово может иметь множественные значения и контекст \"позволяет выбрать\" подходящий смысловой вектор для конркетного случая.\n",
    "[Больше интересной информации вы можете найти в этой статье.](https://habr.com/ru/post/487358/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5c213a-a2d8-458e-a22a-fd8fdd4338df",
   "metadata": {},
   "source": [
    "# Gensim\n",
    "Использовать предобученную модель эмбеддингов или обучить свою можно с помощью библиотеки `gensim`. Вот ее [документация](https://radimrehurek.com/gensim/models/word2vec.html). Вообще-то `gensim` — библиотека для тематического моделирования текстов, но один из компонентов в ней — реализация на python алгоритмов из библиотеки word2vec (которая в оригинале была написана на C++).\n",
    "\n",
    "Если gensim у вас не стоит, то ставим: `pip install gensim`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d6e4c19-0a80-4fe8-920f-53cfbe89b0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.2.0-cp39-cp39-macosx_10_9_x86_64.whl (24.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 24.0 MB 34.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy>=0.18.1 in /Users/u14510182/Documents/python_for_nlp_stud/venv/lib/python3.9/site-packages (from gensim) (1.9.2)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /Users/u14510182/Documents/python_for_nlp_stud/venv/lib/python3.9/site-packages (from gensim) (1.23.2)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /Users/u14510182/Documents/python_for_nlp_stud/venv/lib/python3.9/site-packages (from gensim) (5.2.1)\n",
      "Installing collected packages: gensim\n",
      "Successfully installed gensim-4.2.0\n",
      "\u001b[33mWARNING: You are using pip version 21.1.2; however, version 22.3 is available.\n",
      "You should consider upgrading via the '/Users/u14510182/Documents/python_for_nlp_stud/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a629a13a-f6c6-4cb2-838c-2a896747c827",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import logging\n",
    "import urllib.request\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01059c5b-5b27-4b1d-a5d8-6018210a9da8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Как обучить свою модель\n",
    "\n",
    "Обратите внимание, что тренировка модели не включает препроцессинг! Это значит, что избавляться от пунктуации, приводить слова к нижнему регистру, лемматизировать их, проставлять частеречные теги придется до тренировки модели (если, конечно, это необходимо для вашей задачи). Т.е. в каком виде слова будут в исходном тексте, в таком они будут и в модели.\n",
    "\n",
    "Поскольку иногда тренировка модели занимает много времени, то можно ещё вести лог событий, чтобы понимать, что на каком этапе происходит."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cbf47c3-07dd-474d-bfb0-d45b527289c3",
   "metadata": {
    "id": "DY_Db8XMVEHp"
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42610278-21d7-46dd-ae8d-d0283472a461",
   "metadata": {
    "id": "fm3i7Cc9VEIA"
   },
   "source": [
    "На вход модели даем текстовый файл, каждое предложение на отдельной строчке. Вот игрушечный пример с текстом «Бедной Лизы». Он заранее очищен от пунктуации, приведен к нижнему регистру и лемматизирован."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "025dfcff-8bf5-49f2-8a64-d3d3a93a96fc",
   "metadata": {
    "id": "YUOUR5MHVEID"
   },
   "outputs": [],
   "source": [
    "f = 'liza_lem.txt'\n",
    "data = gensim.models.word2vec.LineSentence(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604affc8-b79f-4f7c-badf-a977c5648df1",
   "metadata": {
    "id": "y9sWIvd_VEIE"
   },
   "source": [
    "Инициализируем модель. Основные параметры:\n",
    "\n",
    "+ данные должны быть итерируемым объектом\n",
    "+ size — размер вектора,\n",
    "+ window — размер окна наблюдения,\n",
    "+ min_count — мин. частотность слова в корпусе,\n",
    "+ sg — используемый алгоритм обучения (0 — CBOW, 1 — Skip-gram),\n",
    "+ sample — порог для downsampling'a высокочастотных слов,\n",
    "+ workers — количество потоков,\n",
    "+ alpha — learning rate,\n",
    "+ iter — количество итераций,\n",
    "+ max_vocab_size — позволяет выставить ограничение по памяти при создании словаря (т.е. если ограничение привышается, то низкочастотные слова будут выбрасываться). Для сравнения: 10 млн слов = 1Гб RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63a8640c-00a8-4ad4-a71f-655d7cd0c00e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WPWburxwVEIJ",
    "outputId": "b3c39d54-076e-44a4-d0d2-1c633a969a2d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-22 13:47:10,671 : INFO : collecting all words and their counts\n",
      "2022-10-22 13:47:10,672 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-10-22 13:47:10,675 : INFO : collected 1213 word types from a corpus of 3109 raw words and 392 sentences\n",
      "2022-10-22 13:47:10,676 : INFO : Creating a fresh vocabulary\n",
      "2022-10-22 13:47:10,679 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=2 retains 478 unique words (39.41% of original 1213, drops 735)', 'datetime': '2022-10-22T13:47:10.679605', 'gensim': '4.2.0', 'python': '3.9.6 (v3.9.6:db3ff76da1, Jun 28 2021, 11:49:53) \\n[Clang 6.0 (clang-600.0.57)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-10-22 13:47:10,680 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 2374 word corpus (76.36% of original 3109, drops 735)', 'datetime': '2022-10-22T13:47:10.680511', 'gensim': '4.2.0', 'python': '3.9.6 (v3.9.6:db3ff76da1, Jun 28 2021, 11:49:53) \\n[Clang 6.0 (clang-600.0.57)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-10-22 13:47:10,684 : INFO : deleting the raw counts dictionary of 1213 items\n",
      "2022-10-22 13:47:10,685 : INFO : sample=0.001 downsamples 83 most-common words\n",
      "2022-10-22 13:47:10,685 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1817.7045543420804 word corpus (76.6%% of prior 2374)', 'datetime': '2022-10-22T13:47:10.685725', 'gensim': '4.2.0', 'python': '3.9.6 (v3.9.6:db3ff76da1, Jun 28 2021, 11:49:53) \\n[Clang 6.0 (clang-600.0.57)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-10-22 13:47:10,691 : INFO : estimated required memory for 478 words and 300 dimensions: 1386200 bytes\n",
      "2022-10-22 13:47:10,691 : INFO : resetting layer weights\n",
      "2022-10-22 13:47:10,693 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-10-22T13:47:10.693386', 'gensim': '4.2.0', 'python': '3.9.6 (v3.9.6:db3ff76da1, Jun 28 2021, 11:49:53) \\n[Clang 6.0 (clang-600.0.57)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2022-10-22 13:47:10,694 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 478 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-10-22T13:47:10.694071', 'gensim': '4.2.0', 'python': '3.9.6 (v3.9.6:db3ff76da1, Jun 28 2021, 11:49:53) \\n[Clang 6.0 (clang-600.0.57)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-10-22 13:47:10,702 : INFO : EPOCH 0: training on 3109 raw words (1778 effective words) took 0.0s, 275522 effective words/s\n",
      "2022-10-22 13:47:10,710 : INFO : EPOCH 1: training on 3109 raw words (1828 effective words) took 0.0s, 580861 effective words/s\n",
      "2022-10-22 13:47:10,718 : INFO : EPOCH 2: training on 3109 raw words (1794 effective words) took 0.0s, 313264 effective words/s\n",
      "2022-10-22 13:47:10,726 : INFO : EPOCH 3: training on 3109 raw words (1808 effective words) took 0.0s, 259899 effective words/s\n",
      "2022-10-22 13:47:10,734 : INFO : EPOCH 4: training on 3109 raw words (1828 effective words) took 0.0s, 486918 effective words/s\n",
      "2022-10-22 13:47:10,735 : INFO : Word2Vec lifecycle event {'msg': 'training on 15545 raw words (9036 effective words) took 0.0s, 223238 effective words/s', 'datetime': '2022-10-22T13:47:10.735090', 'gensim': '4.2.0', 'python': '3.9.6 (v3.9.6:db3ff76da1, Jun 28 2021, 11:49:53) \\n[Clang 6.0 (clang-600.0.57)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-10-22 13:47:10,735 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=478, vector_size=300, alpha=0.025>', 'datetime': '2022-10-22T13:47:10.735606', 'gensim': '4.2.0', 'python': '3.9.6 (v3.9.6:db3ff76da1, Jun 28 2021, 11:49:53) \\n[Clang 6.0 (clang-600.0.57)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 61.9 ms, sys: 10.7 ms, total: 72.7 ms\n",
      "Wall time: 66.3 ms\n"
     ]
    }
   ],
   "source": [
    "%time model_liza = gensim.models.Word2Vec(data, vector_size=300, window=5, min_count=2)#в последней версии vector_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5356cb8e-6c1f-4026-af5e-674fc8e2deb1",
   "metadata": {
    "id": "k5nM8QNkVEIL"
   },
   "source": [
    "Можно нормализовать вектора, тогда модель будет занимать меньше RAM. Однако после этого её нельзя дотренировывать. Здесь используется L2-нормализация: вектора нормализуются так, что если сложить квадраты всех элементов вектора, в сумме получится 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34457554-044b-40a2-90db-cd874541f02a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TOPh3pCZVEIM",
    "outputId": "d743d4c0-d09f-4c9a-e95d-87dde554b4e4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-22 13:48:37,743 : WARNING : destructive init_sims(replace=True) deprecated & no longer required for space-efficiency\n",
      "2022-10-22 13:48:37,745 : INFO : storing 478x300 projection weights into liza.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "model_liza.init_sims(replace=True)\n",
    "model_path = \"liza.bin\"\n",
    "\n",
    "print(\"Saving model...\")\n",
    "model_liza.wv.save_word2vec_format(model_path, binary=True)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44a2ee9-6fbd-4acf-838c-ba0c1a2f05f8",
   "metadata": {
    "id": "oOHpqJghVEIO"
   },
   "source": [
    "Смотрим, сколько в модели слов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d1b6c931-4dc4-4f30-b174-306546aa11f2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pAHJm1FhVEIR",
    "outputId": "60229c9b-ef14-46db-b9fd-f5b63f7bed55"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "478"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(len(model_liza.wv.vocab)) # old\n",
    "len(model_liza.wv.key_to_index) # new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6860d170-f632-427a-b30e-85d55a100890",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d8hCzvr1VEIU",
    "outputId": "8cb7eb94-427e-46f5-ab0b-2c79d42d74da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['анюта', 'армия', 'ах', 'барин', 'бедный', 'белый', 'берег', 'березовый', 'беречь', 'бесчисленный', 'благодарить', 'бледный', 'блеснуть', 'блестящий', 'близ', 'бог', 'богатый', 'большой', 'бояться', 'брать', 'бросать', 'бросаться', 'бывать', 'быть', 'важный', 'ввечеру', 'вдова', 'велеть', 'великий', 'великолепный', 'верить', 'верно', 'весело', 'веселый', 'весна', 'вести', 'весь', 'весьма', 'ветвь', 'ветер', 'вечер', 'взглядывать', 'вздох', 'вздыхать', 'взор', 'взять', 'вид', 'видеть', 'видеться', 'видный', 'вместе', 'вода', 'возвращаться', 'воздух', 'война', 'воображать', 'воображение', 'воспоминание', 'восторг', 'восхищаться', 'время', 'все', 'вслед', 'вставать', 'встречаться', 'всякий', 'высокий', 'выть', 'выходить', 'глаз', 'глубокий', 'гнать', 'говорить', 'год', 'голос', 'гора', 'горе', 'горестный', 'горлица', 'город', 'горький', 'господь', 'гром', 'грусть', 'давать', 'давно', 'далее', 'дверь', 'движение', 'двор', 'девушка', 'дело', 'день', 'деньги', 'деревня', 'деревянный', 'десять', 'добро', 'добрый', 'довольно', 'доживать', 'долго', 'должный', 'дом', 'домой', 'дочь', 'древний', 'друг', 'другой', 'дуб', 'думать', 'душа', 'едва', 'ехать', 'жалобный', 'желание', 'желать', 'жениться', 'жених', 'женщина', 'жестокий', 'живой', 'жизнь', 'жить', 'забава', 'заблуждение', 'забывать', 'завтра', 'задумчивость', 'закраснеться', 'закричать', 'заря', 'здешний', 'здравствовать', 'зеленый', 'земля', 'златой', 'знать', 'ибо', 'играть', 'идти', 'имя', 'искать', 'исполняться', 'испугаться', 'история', 'исчезать', 'кабинет', 'казаться', 'какой', 'капля', 'карета', 'карман', 'картина', 'катиться', 'келья', 'клятва', 'колено', 'копейка', 'который', 'красота', 'крест', 'крестьянин', 'крестьянка', 'кровь', 'кроме', 'кто', 'купить', 'ландыш', 'ласка', 'ласковый', 'левый', 'лес', 'лететь', 'летний', 'лето', 'лиза', 'лизин', 'лизина', 'лицо', 'лишний', 'лодка', 'ложиться', 'луг', 'луч', 'любезный', 'любить', 'любовь', 'лютый', 'матушка', 'мать', 'место', 'месяц', 'мечта', 'милый', 'мимо', 'минута', 'многочисленный', 'могила', 'мой', 'молить', 'молиться', 'молния', 'молодой', 'молодость', 'молчать', 'монастырь', 'море', 'москва', 'москва-река', 'мочь', 'мрак', 'мрачный', 'муж', 'мы', 'мысль', 'наглядеться', 'надеяться', 'надлежать', 'надобно', 'называть', 'наступать', 'натура', 'находить', 'наш', 'небесный', 'небо', 'невинность', 'невинный', 'неделя', 'нежели', 'нежный', 'незнакомец', 'некоторый', 'непорочность', 'неприятель', 'несколько', 'никакой', 'никто', 'новый', 'ночь', 'обижать', 'облако', 'обманывать', 'обморок', 'образ', 'обращаться', 'обстоятельство', 'объятие', 'огонь', 'один', 'однако', 'окно', 'окрестности', 'он', 'она', 'они', 'оно', 'опираться', 'описывать', 'опустеть', 'освещать', 'оставаться', 'оставлять', 'останавливать', 'останавливаться', 'отвечать', 'отдавать', 'отец', 'отечество', 'отменно', 'отрада', 'очень', 'падать', 'память', 'пастух', 'первый', 'перемениться', 'переставать', 'песня', 'петь', 'печальный', 'писать', 'питать', 'плакать', 'побежать', 'побледнеть', 'погибать', 'подавать', 'подгорюниваться', 'подле', 'подозревать', 'подымать', 'поехать', 'пойти', 'показываться', 'поклониться', 'покойный', 'покрывать', 'покрываться', 'покупать', 'полагать', 'поле', 'помнить', 'поселянин', 'последний', 'постой', 'потуплять', 'поцеловать', 'поцелуй', 'правый', 'представляться', 'прежде', 'преклонять', 'прекрасный', 'прелестный', 'приводить', 'прижимать', 'принадлежать', 'принуждать', 'природа', 'приходить', 'приятно', 'приятный', 'провожать', 'продавать', 'проливать', 'простой', 'просыпаться', 'проходить', 'проч', 'прощать', 'прощаться', 'пруд', 'птичка', 'пылать', 'пять', 'работа', 'работать', 'радость', 'рассказывать', 'расставаться', 'рвать', 'ребенок', 'река', 'решаться', 'робкий', 'роза', 'розовый', 'роман', 'российский', 'роща', 'рубль', 'рука', 'сам', 'самый', 'свет', 'светиться', 'светлый', 'свидание', 'свирель', 'свободно', 'свое', 'свой', 'свойство', 'сделать', 'сделаться', 'сей', 'сердечный', 'сердце', 'сидеть', 'сие', 'сиять', 'сказать', 'сказывать', 'сквозь', 'скорбь', 'скоро', 'скрываться', 'слабый', 'слеза', 'слезать', 'слово', 'случаться', 'слушать', 'слышать', 'смерть', 'сметь', 'смотреть', 'собственный', 'соглашаться', 'солнце', 'спасать', 'спокойно', 'спокойствие', 'спрашивать', 'стадо', 'становиться', 'стараться', 'старуха', 'старушка', 'старый', 'статься', 'стена', 'сто', 'столь', 'стон', 'стонать', 'сторона', 'стоять', 'страшно', 'страшный', 'судьба', 'схватывать', 'счастие', 'счастливый', 'сын', 'таить', 'такой', 'твой', 'темный', 'тения', 'тихий', 'тихонько', 'томный', 'тот', 'трава', 'трепетать', 'трогать', 'ты', 'убивать', 'уверять', 'увидеть', 'увидеться', 'удерживать', 'удивляться', 'удовольствие', 'узнавать', 'улица', 'улыбка', 'уметь', 'умирать', 'унылый', 'упасть', 'услышать', 'утешение', 'утро', 'хижина', 'хлеб', 'ходить', 'холм', 'хороший', 'хотеть', 'хотеться', 'хотя', 'худо', 'худой', 'царь', 'цветок', 'целовать', 'час', 'часто', 'человек', 'чистый', 'читатель', 'чувствительный', 'чувство', 'чувствовать', 'чулок', 'шестой', 'шум', 'шуметь', 'щадить', 'щека', 'эраст', 'эрастов', 'это', 'я']\n"
     ]
    }
   ],
   "source": [
    "print(sorted([w for w in model_liza.wv.key_to_index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e56162-813a-4c1d-bea2-c3183483009c",
   "metadata": {
    "id": "q0sQjKiTVEIY"
   },
   "source": [
    "И чему же мы ее научили? Попробуем оценить модель вручную, порешав примеры. Несколько дано ниже, попробуйте придумать свои."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ee650541-ccec-43ef-83bc-36ace809632d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8bJE4Jc4VEIZ",
    "outputId": "a26b3425-993a-451b-844e-6e88bd8b3ddf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('проходить', 0.18653517961502075)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_liza.wv.most_similar(positive=[\"смерть\", \"любовь\"], negative=[\"печальный\"], topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4a4dfff6-0b9a-417f-b33d-3fd7cdbbf229",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yIU8YNA_VEIa",
    "outputId": "6dc633d8-9f76-4943-d523-ce4bd4dece05"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('выть', 0.2030768096446991),\n",
       " ('нежный', 0.1860518455505371),\n",
       " ('лодка', 0.1758255660533905)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_liza.wv.most_similar(\"любовь\", topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7f7555eb-c183-4985-9682-7d3e061c630f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lOGRhxfnVEIc",
    "outputId": "fed60e6f-be80-4490-a67c-10d6ac04a23f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14449573"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_liza.wv.similarity(\"лиза\", \"эраст\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "afd1bc5d-42a3-4159-8105-5f1caca1ad71",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "4tmwGsoHVEId",
    "outputId": "54bca41e-f13d-46d0-c456-5ab106b906b9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'слеза'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_liza.wv.doesnt_match(\"скорбь грусть слеза улыбка\".split())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301be455-ae3f-4def-b5c1-b05530891bf5",
   "metadata": {
    "id": "EZl_fECYVEIh"
   },
   "source": [
    "#### Параметры варьирования\n",
    "\n",
    "1) препроцессинг -- лемматизировать или нет, например, вдруг мы хотим посмотреть на морфологические пропорции? тогда лемматизировать не нужно\n",
    "\n",
    "2) размер корпуса -- чем больше, тем лучше, но! не для семантических задач -- для них важнее качество\n",
    "\n",
    "3) размер словаря\n",
    "\n",
    "4) negative samples\n",
    "\n",
    "5) количество итераций\n",
    "\n",
    "6) длина вектора -- 100-300 (судя по всему, >300 не сильно улучшает результаты)\n",
    "\n",
    "7) длина окна -- для синтаксических задач, примерно 4, для семантических задач, большое окно, 8, 10.\n",
    "\n",
    "Хорошая статья про сравнение моделей с варьированием параметров: https://www.aclweb.org/anthology/D14-1162.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4693ae5-7fe3-47ba-8562-65a9e7e51428",
   "metadata": {
    "id": "vPsDlgqQVEIj"
   },
   "source": [
    "#### Как использовать готовую модель\n",
    "\n",
    "#### RusVectōrēs\n",
    "\n",
    "На сайте RusVectōrēs (https://rusvectores.org/ru/) собраны предобученные на различных данных модели для русского языка, а также можно поискать наиболее близкие слова к заданному, посчитать семантическую близость нескольких слов и порешать примеры с помощью «калькулятором семантической близости».\n",
    "\n",
    "Для других языков также можно найти предобученные модели — например, модели [fastText](https://fasttext.cc/docs/en/english-vectors.html) и [GloVe](https://nlp.stanford.edu/projects/glove/)\n",
    "\n",
    "Ещё давайте посмотрим на **векторные романы** https://nevmenandr.github.io/novel2vec/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0705099c-00ec-4a59-ae00-f89292c8262e",
   "metadata": {
    "id": "v290agZHVEIk",
    "tags": []
   },
   "source": [
    "#### Работа с моделью\n",
    "\n",
    "Модели word2vec бывают разных форматов:\n",
    "\n",
    "+ .vec.gz — обычный файл\n",
    "+ .bin.gz — бинарник\n",
    "\n",
    "Загружаются они с помощью одного и того же класса `KeyedVectors`, меняется только параметр `binary` у функции `load_word2vec_format`.\n",
    "\n",
    "Если же эмбеддинги обучены не с помощью word2vec, то для загрузки нужно использовать функцию `load`. Т.е. для загрузки предобученных эмбеддингов `glove`, `fasttext`, `bpe` и любых других нужна именно она.\n",
    "\n",
    "Скачаем с RusVectōrēs модель для русского языка, обученную на НКРЯ образца 2015 г."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e15a4d-bc49-408a-ba19-abad2ef33aed",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DfgQDJYjVEIn",
    "outputId": "1ec78923-d60a-45d4-fa25-c49a4f6bfd41"
   },
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 403: Forbidden",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [28]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43murllib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhttp://rusvectores.org/static/models/rusvectores2/ruscorpora_mystem_cbow_300_2_2015.bin.gz\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mruscorpora_mystem_cbow_300_2_2015.bin.gz\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/urllib/request.py:239\u001b[0m, in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;124;03mRetrieve a URL into a temporary location on disk.\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;124;03mdata file as well as the resulting HTTPMessage object.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    237\u001b[0m url_type, path \u001b[38;5;241m=\u001b[39m _splittype(url)\n\u001b[0;32m--> 239\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mclosing(\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[1;32m    240\u001b[0m     headers \u001b[38;5;241m=\u001b[39m fp\u001b[38;5;241m.\u001b[39minfo()\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;66;03m# Just return the local path and the \"headers\" for file://\u001b[39;00m\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;66;03m# URLs. No sense in performing a copy unless requested.\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/urllib/request.py:214\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    213\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[0;32m--> 214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/urllib/request.py:523\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_response\u001b[38;5;241m.\u001b[39mget(protocol, []):\n\u001b[1;32m    522\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[0;32m--> 523\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/urllib/request.py:632\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[0;32m--> 632\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/urllib/request.py:561\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[1;32m    560\u001b[0m     args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp_error_default\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m orig_args\n\u001b[0;32m--> 561\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/urllib/request.py:494\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[1;32m    493\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 494\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    495\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    496\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/urllib/request.py:641\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[0;32m--> 641\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req\u001b[38;5;241m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 403: Forbidden"
     ]
    }
   ],
   "source": [
    "urllib.request.urlretrieve(\"http://rusvectores.org/static/models/rusvectores2/ruscorpora_mystem_cbow_300_2_2015.bin.gz\", \"ruscorpora_mystem_cbow_300_2_2015.bin.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47ccd28c-fe09-438a-ae89-8e93777fd72c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RdJc7-q6VEIq",
    "outputId": "2f633668-9e2c-4b45-8898-431b80c8235f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-13 06:34:39,254 : INFO : loading projection weights from ruscorpora_mystem_cbow_300_2_2015.bin.gz\n",
      "2021-10-13 06:34:53,828 : INFO : loaded (281776, 300) matrix from ruscorpora_mystem_cbow_300_2_2015.bin.gz\n"
     ]
    }
   ],
   "source": [
    "m = 'ruscorpora_mystem_cbow_300_2_2015.bin.gz'\n",
    "\n",
    "if m.endswith('.vec.gz'):\n",
    "    model = gensim.models.KeyedVectors.load_word2vec_format(m, binary=False)\n",
    "elif m.endswith('.bin.gz'):\n",
    "    model = gensim.models.KeyedVectors.load_word2vec_format(m, binary=True)\n",
    "else:\n",
    "    model = gensim.models.KeyedVectors.load(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33f3583-2f25-4f22-ad0d-1b03dfee9c9d",
   "metadata": {
    "id": "w3UV2ZV4VEIr"
   },
   "source": [
    "**Мини-исследование**: Давайте протестируем, выделяет ли модель функцию интенсификации в прилагательных? Например, *ужасный курильщик* может интерпретироваться как *человек, который много курит*, а не только как (не столько как) *очень плохой человек-курильщик*. Объединяет ли модель *плохой, ужасный, жуткий, страшный* по отрицательной полярности и объединяет ли она *ужасный, жуткий, страшный* по функции интенсификации?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1fa29937-2028-4efd-b88b-bfa447f428e8",
   "metadata": {
    "id": "_KWmL5JSVEIs"
   },
   "outputs": [],
   "source": [
    "words = ['хороший_A', 'плохой_A', 'ужасный_A','жуткий_A', 'страшный_A', 'красный_A', 'синий_A']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734f0ec0-389e-4fea-bae9-9b9e782aa555",
   "metadata": {
    "id": "YxKyzxJ_VEIt"
   },
   "source": [
    "Частеречные тэги нужны, поскольку это специфика скачанной модели - она была натренирована на словах, аннотированных их частями речи (и лемматизированных). NB! В названиях моделей на `rusvectores` указано, какой тегсет они используют (mystem, upos и т.д.)\n",
    "\n",
    "Попросим у модели 10 ближайших соседей для каждого слова и коэффициент косинусной близости для каждого:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b799adb8-eac2-437d-9754-d6777adc53f6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xiZ2jQHEVEIu",
    "outputId": "0098036c-d2dc-4488-888a-7072c5fcdbb9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-13 06:35:02,031 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "хороший_A\n",
      "[ 0.00722357 -0.00361956  0.1272455   0.06584469  0.00709477 -0.02014845\n",
      " -0.02056034  0.01321563  0.13692418 -0.09624264]\n",
      "плохой_A 0.7463520765304565\n",
      "неплохой_A 0.6708558797836304\n",
      "отличный_A 0.6633436679840088\n",
      "превосходный_A 0.6079519987106323\n",
      "замечательный_A 0.586450457572937\n",
      "недурной_A 0.5322482585906982\n",
      "отменный_A 0.5168066024780273\n",
      "прекрасный_A 0.4982393980026245\n",
      "посредственный_A 0.49099433422088623\n",
      "приличный_A 0.48622459173202515\n",
      "\n",
      "\n",
      "плохой_A\n",
      "[-0.05218472  0.0307817   0.1459371   0.0151835   0.06219714  0.01153753\n",
      " -0.01169093  0.01818374  0.0955373  -0.10191503]\n",
      "хороший_A 0.7463520765304565\n",
      "дурной_A 0.6186875104904175\n",
      "скверный_A 0.6014161109924316\n",
      "отличный_A 0.5226833820343018\n",
      "посредственный_A 0.5061030983924866\n",
      "неважный_A 0.5021152496337891\n",
      "неплохой_A 0.49169060587882996\n",
      "никудышный_A 0.48035892844200134\n",
      "ухудшать_V 0.43680477142333984\n",
      "плохо_ADV 0.4314875304698944\n",
      "\n",
      "\n",
      "ужасный_A\n",
      "[-0.05553271 -0.03172469  0.01998607  0.00171507 -0.00935555 -0.0296017\n",
      "  0.05394973  0.01597532 -0.03785459 -0.02099892]\n",
      "страшный_A 0.8007251024246216\n",
      "жуткий_A 0.6982528567314148\n",
      "отвратительный_A 0.6798903942108154\n",
      "ужасающий_A 0.6174501180648804\n",
      "чудовищный_A 0.6100856065750122\n",
      "постыдный_A 0.6009703278541565\n",
      "невероятный_A 0.5827822685241699\n",
      "ужасать_V 0.5815353393554688\n",
      "кошмарный_A 0.5675790309906006\n",
      "позорный_A 0.5351496338844299\n",
      "\n",
      "\n",
      "жуткий_A\n",
      "[-0.07627533 -0.06143281 -0.02622319 -0.03769541 -0.00350412 -0.01479934\n",
      "  0.03325103  0.06712756 -0.0044996   0.0145266 ]\n",
      "ужасный_A 0.6982529163360596\n",
      "страшный_A 0.6917036771774292\n",
      "зловещий_A 0.6490101218223572\n",
      "странный_A 0.6009964942932129\n",
      "отвратительный_A 0.5856714248657227\n",
      "тоскливый_A 0.5783498287200928\n",
      "кошмарный_A 0.5670032501220703\n",
      "гнетущий_A 0.5607054829597473\n",
      "чудовищный_A 0.5550791025161743\n",
      "мрачный_A 0.5542315244674683\n",
      "\n",
      "\n",
      "страшный_A\n",
      "[-0.12759186 -0.0206753   0.00979353 -0.02963523  0.03109632  0.02121338\n",
      " -0.02869159  0.02574235 -0.02556899 -0.03742376]\n",
      "ужасный_A 0.8007251620292664\n",
      "жуткий_A 0.6917036175727844\n",
      "чудовищный_A 0.5934231877326965\n",
      "кошмарный_A 0.539563000202179\n",
      "отвратительный_A 0.5351147651672363\n",
      "невероятный_A 0.5207849144935608\n",
      "ужасающий_A 0.5174921154975891\n",
      "зловещий_A 0.5163233876228333\n",
      "жестокий_A 0.5096044540405273\n",
      "ужасать_V 0.5071669816970825\n",
      "\n",
      "\n",
      "красный_A\n",
      "[ 0.01627072 -0.01136785 -0.00790482  0.02294072  0.05129128  0.10162549\n",
      "  0.07488654 -0.06475785 -0.0203686   0.09159683]\n",
      "алый_A 0.6421287059783936\n",
      "малиновый_A 0.6113021373748779\n",
      "красная_S 0.5526680946350098\n",
      "желтый_A 0.5431625843048096\n",
      "оранжевый_A 0.5371882319450378\n",
      "трехцветный_A 0.5317935347557068\n",
      "пунцовый_A 0.5125025510787964\n",
      "синий_A 0.5102002024650574\n",
      "фиолетовый_A 0.5072877407073975\n",
      "лиловый_A 0.5004071593284607\n",
      "\n",
      "\n",
      "синий_A\n",
      "[-0.00614284  0.04970241 -0.00461786 -0.11465221  0.08177482  0.00020589\n",
      "  0.04895581  0.02750725 -0.05211812  0.06006202]\n",
      "голубой_A 0.855513334274292\n",
      "темно-синий_A 0.7498062252998352\n",
      "оранжевый_A 0.7341034412384033\n",
      "лиловый_A 0.7314398884773254\n",
      "фиолетовый_A 0.7291390895843506\n",
      "желтый_A 0.7263568639755249\n",
      "ярко-синий_A 0.699012815952301\n",
      "черный_A 0.690920889377594\n",
      "зеленый_A 0.6799379587173462\n",
      "коричневый_A 0.6729934215545654\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    # есть ли слово в модели? \n",
    "    if word in model:\n",
    "        print(word)\n",
    "        # смотрим на вектор слова (его размерность 300, смотрим на первые 10 чисел)\n",
    "        print(model[word][:10])\n",
    "        # выдаем 10 ближайших соседей слова:\n",
    "        for i in model.most_similar(positive=[word], topn=10):\n",
    "            # слово + коэффициент косинусной близости\n",
    "            print(i[0], i[1])\n",
    "        print('\\n')\n",
    "    else:\n",
    "        # Увы!\n",
    "        print('Увы, слова \"%s\" нет в модели!' % word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c897d16e-7524-47ac-8476-148db60df173",
   "metadata": {
    "id": "2Mdpu0ztVEIv"
   },
   "source": [
    "Находим косинусную близость пары слов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e741dca4-a095-48e8-811f-58add50068f1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "37gfNT_-VEIw",
    "outputId": "0251bf5f-2d93-431d-ffd6-4c34cfe6cc5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.74635214\n"
     ]
    }
   ],
   "source": [
    "print(model.similarity('плохой_A', 'хороший_A'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3a4a7a1c-799e-47d5-9165-182dd35efc55",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gF1gSK93VEIy",
    "outputId": "3129f4f1-29e3-486a-a271-619140718133"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.12778337\n"
     ]
    }
   ],
   "source": [
    "print(model.similarity('плохой_A', 'синий_A'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c11ab6e-39af-4442-9cd0-8e9c303c3d76",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vdIxSXfpVEIz",
    "outputId": "13872e05-029c-4eed-942c-afe20cb6416b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.69825286\n"
     ]
    }
   ],
   "source": [
    "print(model.similarity('ужасный_A', 'жуткий_A'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca713f79-37cc-427d-9eb3-9bf84c7923cb",
   "metadata": {
    "id": "IN24380IVEI0"
   },
   "source": [
    "Попробуем составить пропорцию:\n",
    "\n",
    "+ positive — вектора, которые мы складываем\n",
    "+ negative — вектора, которые вычитаем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ce306431-55e0-447f-8046-dab11a7b8813",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4_8WiWZpVEI1",
    "outputId": "d882392f-96b0-41e5-a7b7-af07a956d207"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "страшный_A\n"
     ]
    }
   ],
   "source": [
    "print(model.most_similar(positive=['плохой_A', 'ужасный_A'], negative=['хороший_A'])[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d4f92f-cd3b-4709-8096-c22bfcc41dd7",
   "metadata": {
    "id": "F5VLNFUhVEI2"
   },
   "source": [
    "Найди лишнее!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "938d2485-6f4e-4dd1-899b-e4bef62347e1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U1Eqd1B2VEI4",
    "outputId": "32b8cb69-d968-4817-a014-d63ca4cdf5ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "хороший_A\n"
     ]
    }
   ],
   "source": [
    "print(model.doesnt_match('плохой_A хороший_A ужасный_A страшный_A'.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "781e1d39-b1a5-4d61-a223-86884d202c3a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Da5fov1DVEI5",
    "outputId": "2319db02-f2ff-4ded-ad0d-37fd19504570"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "плохой_A\n"
     ]
    }
   ],
   "source": [
    "print(model.doesnt_match('плохой_A ужасный_A страшный_A'.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "63eccb22-111b-405b-b406-70118335ece3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XJndzvCqVEI6",
    "outputId": "f7d650b5-470c-450f-acd1-cd209806cf25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5575\tбезумно_ADV\n",
      "0.4791\tбезмерно_ADV\n",
      "0.4536\tжутко_ADV\n",
      "0.4472\tневероятно_ADV\n",
      "0.4394\tочень_ADV\n",
      "0.4364\tчертовски_ADV\n",
      "0.4231\tстрашно_ADV\n",
      "0.4124\tнеобычайно_ADV\n",
      "0.4119\tнестерпимо_ADV\n",
      "0.4005\tнеобыкновенно_ADV\n"
     ]
    }
   ],
   "source": [
    "for word, score in model.most_similar(positive=['ужасно_ADV'], negative=['плохой_A']):\n",
    "    print(f'{score:.4}\\t{word}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e03bcb0-52ef-4c3a-a801-1c3e3aee617b",
   "metadata": {
    "id": "-R0i47cLVEI7"
   },
   "source": [
    "Что означают полученные результаты для нашего исследования? Объединяет ли модель *плохой, ужасный, жуткий, страшный* по отрицательной полярности и объединяет ли она *ужасный, жуткий, страшный* по функции интенсификации?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bcacdb-0a52-4f1c-a837-eb01b917d48b",
   "metadata": {
    "id": "PjRcz2nrVEI8"
   },
   "source": [
    "### Визуализация\n",
    "\n",
    "Можно использовать разные методы того, как преобразовать векторы так, чтобы можно было их поместить на двумерное пространство, например, с помощью PCA. В зависимости от того, относительно какого набора слов вы пытаетесь найти оптимально отображение на двумерное пространство, у вас могут получаться разные результаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5e04726b-86a0-414d-8950-895bbe96e21f",
   "metadata": {
    "id": "DTpnk9BsVEI9"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2bc5f953-09fc-4630-9cac-c22581964caf",
   "metadata": {
    "id": "GVk5tY3WVEI-"
   },
   "outputs": [],
   "source": [
    "words = ['хороший_A', 'плохой_A', 'ужасный_A','жуткий_A', 'страшный_A', 'красный_A', 'синий_A']\n",
    "X = model[words]#model.wv[words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "390ea43b-9688-4a57-b2fc-afc7842d0b89",
   "metadata": {
    "id": "QHCQntR-VEI_"
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "coords = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b5bc9728-9174-4576-9807-eff537f5fe84",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "hVia6FDvVEJD",
    "outputId": "aadb2d0d-462a-4ee6-9eb6-c3d1124710b7"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(coords[:, 0], coords[:, 1], color='red')\n",
    "plt.title('Words')\n",
    "\n",
    "for i, word in enumerate(words):\n",
    "    plt.annotate(word, xy=(coords[i, 0], coords[i, 1]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7086f231-0926-4772-b396-76e6a5e9d1fe",
   "metadata": {
    "id": "TAJ4CiDDVEJJ"
   },
   "source": [
    "#### Оценка\n",
    "\n",
    "Это, конечно, хорошо, но как понять, какая модель лучше? Или вот, например, я сделал свою модель, а как понять, насколько она хорошая?\n",
    "\n",
    "Для этого существуют специальные датасеты для оценки качества дистрибутивных моделей. Основных два: один измеряет точность решения задач на аналогии, а второй используется для оценки коэффициента семантической близости.\n",
    "\n",
    "#### Word Similarity\n",
    "\n",
    "Этот метод заключается в том, чтобы оценить, насколько представления о семантической близости слов в модели соотносятся с \"представлениями\" людей.\n",
    "\n",
    "| слово 1    | слово 2    | близость |\n",
    "|------------|------------|----------|\n",
    "| кошка      | собака     | 0.7      | \n",
    "| чашка      | кружка     | 0.9      | \n",
    "\n",
    "Для каждой пары слов из заранее заданного датасета мы можем посчитать косинусное расстояние, и получить список таких значений близости. При этом у нас уже есть список значений близостей, сделанный людьми. Мы можем сравнить эти два списка и понять, насколько они похожи (например, посчитав корреляцию). Эта мера схожести должна говорить о том, насколько модель хорошо моделирует расстояния о слова.\n",
    "\n",
    "#### Аналогии\n",
    "\n",
    "Другая популярная задача для \"внутренней\" оценки называется задачей поиска аналогий. Как мы уже разбирали выше, с помощью простых арифметических операций мы можем модифицировать значение слова. Если заранее собрать набор слов-модификаторов, а также слов, которые мы хотим получить в результаты модификации, то на основе подсчёта количества \"попаданий\" в желаемое слово мы можем оценить, насколько хорошо работает модель.\n",
    "\n",
    "В качестве слов-модификатор мы можем использовать семантические аналогии. Скажем, если у нас есть некоторое отношение \"страна-столица\", то для оценки модели мы можем использовать пары наподобие \"Россия-Москва\", \"Норвегия-Осло\", и т.д. Датасет будет выглядеть следующм образом:\n",
    "\n",
    "| слово 1    | слово 2    | отношение     | \n",
    "|------------|------------|---------------|\n",
    "| Россия     | Москва     | страна-столица| \n",
    "| Норвегия   | Осло       | страна-столица|\n",
    "\n",
    "Рассматривая случайные две пары из этого набора, мы хотим, имея триплет (Россия, Москва, Норвегия) хотим получить слово \"Осло\", т.е. найти такое слово, которое будет находиться в том же отношении со словом \"Норвегия\", как \"Россия\" находится с Москвой.\n",
    "\n",
    "Датасеты для русского языка можно скачать на странице с моделями на RusVectores. Посчитаем качество нашей модели НКРЯ на датасете про аналогии:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbcf40a-1944-4276-8224-4adb885de2e1",
   "metadata": {
    "id": "Uy2hyRVnVEJK"
   },
   "outputs": [],
   "source": [
    "# res = model.accuracy('ru_analogy_tagged.txt') # работает для старых версий gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e669eb0f-c9fe-4c56-9df4-bdd446d8583e",
   "metadata": {
    "id": "VQt_47fgVEJL"
   },
   "outputs": [],
   "source": [
    "# for row in res[4]['incorrect'][:10]:\n",
    "#     print('\\t'.join(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53970ef-fda7-4908-9b96-53375b7c2633",
   "metadata": {
    "id": "DCRWEaEuVEJL"
   },
   "source": [
    "#### Задание 1\n",
    "\n",
    "+ Возьмите небольшой кусочек текста или стихотворение.\n",
    "+ Замените все неслужебные слова в нём на их ближайших соседей из нашей модели.\n",
    "+ Прокомментируйте результат.\n",
    "\n",
    "#### Задание 2\n",
    "\n",
    "+ Возьмите интересный Вам текст.\n",
    "+ Лемматизируйте текст, отчистите от пунктуации и служебной информации и обучите на нем модель word2vec (поэкспериментируйте с размером окна, с длиной вектора). \n",
    "+ Найдите по 5 ближайших слов к нескольким интересующим Вас словам. Обязательно попробуйте взять слова различной частеречной принадлежности, различных семантических классов (абстрактные слова, экспрессивы). Учтите, что слова может не быть в модели!\n",
    "+ Найдите по 5 \"далёких\" слов к нескольким интересующим Вас словам. Обязательно попробуйте взять слова различной частеречной принадлежности, различных семантических классов (абстрактные слова, экспрессивы).\n",
    "+ Прокомментируйте результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569a1d2d-8fa6-4d3a-a67f-ff0dce4bd3c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c64f4d5-8c9d-4110-bcf9-4289c7eda83f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
