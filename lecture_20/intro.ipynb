{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Машинное обучение\n",
    "\n",
    "Машинное обучение - метод решения задаче не через прямые инструкции и правила, а через нахождение зависимостей на множестве примеров.\n",
    "Вы даете на вход алгоритму наблюдаемые примеры, он учится находить в них зависимости.\n",
    "\n",
    "\n",
    "## Типы обучения\n",
    "\n",
    "Мы будем рассматривать два класса:\n",
    "\n",
    "**Обучение с учителем** - это обучение на парах набор признаков + правильный ответ.\n",
    "\n",
    "Примеры:\n",
    "\n",
    "1. Есть набор размеченных текстов, где есть пары оригинал текста + метка спам или не спам.\n",
    "2. Определение части речи, где есть слова + метки части речи к каждому\n",
    "3. Есть характеристики домов (кол-во комнат, квадратные метры) и цена, задача - научиться по параметрам предсказывать цену\n",
    "\n",
    "**Обучение без учителя** - это обучение, когда нет правильного ответа, а просто есть набор признаков.\n",
    "\n",
    "1. Есть много текстов, нужно найти, какие есть группы похожих между собой текстов в этом наборе\n",
    "\n",
    "\n",
    "Обозначим данные (признаки) за **X**, а целевую переменную, которую будем предсказыва за **y**.\n",
    "\n",
    "\n",
    "## Выборка\n",
    "\n",
    "Выборка - это набор данных, то есть каких-либо описаний объектов.\n",
    "Как правило весь набор данных бьют на три выборки:\n",
    "- обучающая, на ней мы обучаем нашу модель\n",
    "- тестовая, с помощью нее мы подбираем гиперпараметры модели\n",
    "- валидационная, на ней проверяют итоговое качество модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задачи и методы машинного обучения\n",
    "\n",
    "\n",
    "### Регрессия\n",
    "\n",
    "Регрессия - это задача предсказания некоторого числа: как из набора признаков (чисел) получить желаемое число.\n",
    "\n",
    "Например, по площади квартиры и кол-ву комнат предсказать стоимость. Здесь площадь и число комнат - это признаки или независимые переменные, а цена - это целевая (независимая) переменная, которую мы бдет предсказывать. \n",
    "\n",
    "\n",
    "**Линейная регрессия**\n",
    "\n",
    "Линейная регрессия - это метод, который стремится найти коэффициенты, с которыми можно сложить наши признаки, чтобы получить нашу целевую переменную (**y**). Ищем коэффициенты в линейном уравнении типа $$b0 + b1*x1 ... = y$$\n",
    "\n",
    "**X** - числа, например, количество комнат, площадь, наличие кондиционера (0 - нет, 1 - да)\n",
    "**y** - число, например, цена\n",
    "\n",
    "Например, найти такие b0, b1, b2, чтобы на наших данных формула\n",
    "\n",
    "$$b0 + b1 * nrooms + b2 * sqrm = price$$\n",
    "\n",
    "b0 - свободный член в линейном уравнении\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/b/be/Normdist_regression.png\">\n",
    "Источник: Википедия\n",
    "\n",
    "\n",
    "### Классификация\n",
    "\n",
    "Классификация - это задача разделения на группы. Можно делить на две группы или на несколько.\n",
    "\n",
    "Например:\n",
    "\n",
    "- классификация спам / не-спам\n",
    "- анализ тональности (негативный, нейтральный, позитивный)\n",
    "- классификация новостей по рубрикам (политика, наука, культура)\n",
    "\n",
    "**X** - числа или категории (зависит от метода)\n",
    "**y** - категория\n",
    "\n",
    "\n",
    "**Логистическая регрессия**\n",
    "\n",
    "Логистическая регрессия в чем-то напоминает линейную, но она предсказывает не число, а вероятность наступления события. Обычно используется для бинарной классификации (на два класса), где вероятность - это вероятность принадлежать ко второму классу, а 1 - y = вероятность принадлежать к первому. Может быть использована с доработками и для многоклассовой классификации.\n",
    "\n",
    "Например, классификация спама: получить вероятность того, что это спам\n",
    "\n",
    "У нас есть результат работы TF-IDF и на основании этих признаков мы предсказываем вероятность того, что это спам.\n",
    "\n",
    "\n",
    "**KNN - метод ближайших соседей**\n",
    "\n",
    "KNN запоминает координаты каждого объекта, значения его признаков - это координаты точки в многомерном пространстве (если 3 признака, то трехмерное, если N, то N-мерное, как с векторами). Берем K ближайших точек (например, 5) и смотрим, какая метка класса самая частая - это и есть наше предсказание.\n",
    "\n",
    "Например, мы находим тексты, где распределение слов похожее и предсказываем самую популярную для них рубрику. Допустим, что у текста ближайшие соседи [политика, искусство, искусство, искусство, наука], предсказываем искусство.\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/e/e7/KnnClassification.svg?uselang=ru\">\n",
    "Источник: Википедия\n",
    "\n",
    "\n",
    "**Decision Tree - Деревья решений**\n",
    "\n",
    "Пытаемся найти спооб создать набор простые правил да / нет, чтобы выделить достаточно однородные группы и для объектов, которые в них попадают, давать наиболее вероятный ответ.\n",
    "\n",
    "Могут работать с категориальными переменными и могут быть использованы для построения регрессии.\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/690/1*xzF10JmR3K0rnZ8jtIHI_g.png\">\n",
    "\n",
    "Источник: towardsdatascience.com\n",
    "\n",
    "**Random Forest - Случайный лес**\n",
    "\n",
    "Метод, который использует набор деревьев, каждое из которых получает только часть данных, что делает алгоритм более устойчивым к изменениям и решает ряд проблем.\n",
    "\n",
    "\n",
    "### Кластеризация\n",
    "\n",
    "Кластеризация - это задача нахождения групп. У нас нет правильных ответов, только набор признаков. Мы стараемся анйти группы похожих друг на друга объектов.\n",
    "\n",
    "**K-means - метод K средних**\n",
    "\n",
    "Метод, в котором мы задаем, сколько групп хотим найти и он подбирает центры кластеров. Любая точка относится к той группе, к центру которой она ближе всего находится.\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/e/ea/K-means_convergence.gif\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оценка качества модели\n",
    "\n",
    "Чтобы понять, хорошо ил инет работает модель, нужно использовать какие-то инструменты измерения качества - это метрики. Для разных методов есть разные способы измерять качество.\n",
    "\n",
    "\n",
    "### Метрики качества\n",
    "\n",
    "**MSE / RMSE** ([root] mean squared error) - среднеквадратическая (-ичная) ошибка (или корень из нее). Используется в регрессии, чтобы оценить, насколько наша прямая (для линейной регрессии) хорошо описывает данные, то есть как далеко от нее находятся точки данных.\n",
    "\n",
    "$$\\sqrt{\\frac{1}{n}\\Sigma_{i=1}^{n}{\\Big(\\frac{xpred_i - xtrue_i}{\\sigma_i}\\Big)^2}}$$\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1222/1*jopCO2kMEI84s6fiGKdXqg.png\">\n",
    "\n",
    "Источник: Medium\n",
    "\n",
    "**R2** - доля дисперсии зависимой переменной, объясняемая рассматриваемой моделью зависимости, мера того, насколько лучше модель описывает различия в данных по сравнению с модель, которая просто выдает среднее по всем (дисперсия общая). Используется в регрессии.\n",
    "\n",
    "<img src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/6b863cb70dd04b45984983cb6ed00801d5eddc94\">\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/8/86/Coefficient_of_Determination.svg/1920px-Coefficient_of_Determination.svg.png\">\n",
    "Источник: Википедия\n",
    "\n",
    "\n",
    "**Accuracy** - точность, доля правильных ответов, используется в классификации.\n",
    "\n",
    "Например, есть 10 объектов, для 8 из них модель правильно поставила метку класса, получается качество 0.8.\n",
    "\n",
    "Если у нас классы несбалансированные, например, 99% не спам, 1% спам, то эта метрика не подходит, так как даже если мы ничего как спам не пометим, у нас уже качество 99%. А вот если 50% + 50%, тогда ок использовать такую метрику.\n",
    "\n",
    "\n",
    "Дальше мы работаем с матрицей ошибок (confusion matrix). Представим, что мы работаем с задачей, где спам - это положительный ответ, не спам - это отрицательный ответ.\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/625/1*fxiTNIgOyvAombPJx5KGeA.png\">\n",
    "Источник: towardsdatascience\n",
    "\n",
    "TP - true positive - истинно положительные - спам и помечен как спам\n",
    "TN - true negative - истинно ложные - не спам и помечен как не спам\n",
    "FP - false positive - ложноположительные - не спам, но помечен как спам\n",
    "FN - false negative - ложноотрицательные - спам, но помечен как не спам\n",
    "\n",
    "**Precision** - тоже точность, но это сколько правильных ответов из тех, которые помечены как спам (сколько действительно спам).\n",
    "\n",
    "Precision = TP / (TP + FP)\n",
    "\n",
    "Если хорошие письма не попадают в спам, то у нас идеальныцй precision, даже если мы какой-то спам пропускаем и показываем в почте.\n",
    "\n",
    "**Recall** - полнота, сколько из всех положительных мы помечаем как положительные. Сколько спама из всего реального спама мы помечаем как спам.\n",
    "\n",
    "Если весь спам попадает в спам, то у нас идеальный recall, даже если хорошие письма тоже в спам попадают.\n",
    "\n",
    "\n",
    "**F1 Score** - метрика, которая использует оба параметра, это дает более информативную метрику. Если у нас идет перекос по precision или recall это отразится в метрике и не будет случаев, когда все подряд помечается как спам или весь спам попадает во входящие.\n",
    "\n",
    "$$F1 = 2 * \\frac{precision * recall}{precision + recall}$$\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/Precisionrecall.svg/800px-Precisionrecall.svg.png\" style=\"max-height: 600px\">\n",
    "Источник: Википедия\n",
    "\n",
    "\n",
    "### На каких данных измерять\n",
    "\n",
    "Модель может переобучаться, то есть слишком точно настраиваться на данные из обучающей выборки или недообучаться, когда мы недостаточно точно описываем данные.\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/3000/1*_7OPgojau8hkiPUiHoGK_w.png\">\n",
    "Источник: Medium\n",
    "\n",
    "Чтобы понять, как модель себя ведет \"в дикой природе\" на новых данных, которые она еще не видела, нужно отложить некоторые данные, которые модель не видит в процессе обучения. Это можно сделать несоклькими способами.\n",
    "\n",
    "**Отложенная выборка**\n",
    "\n",
    "Делим выборку на 2 части: обучающая и тестовая. Тестовая никак не задействована в обучении. Обучаемся один раз на обучающей и проверяем на тестовой.\n",
    "\n",
    "Обычно соотношение 80:20, 70:30, 90:10\n",
    "\n",
    "**Кросс-валидация**\n",
    "\n",
    "Делим выборку на N частей и по очереди каждую из этих частей откладываем и обучаем на остальных.\n",
    "\n",
    "**Leave One Out**\n",
    "\n",
    "То же самое, но делим на столько частей, сколько объектов в данных. Подходит для маленьких датасетов, где мы не можем позволить себе выкидывать 10-20% данных и можем позволить себе много раз обучать модель быстро.\n",
    "\n",
    "<img src=\"https://scikit-learn.org/stable/_images/grid_search_cross_validation.png\">\n",
    "Источник: scikit-learn.org\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Святая троица - Модель, Функция потерь, Метод оптимизации\n",
    "**Цель модели по входным данным выдать ответ, на поставленный перед ней вопрос/задачу.**  \n",
    "Назовем модель буквой M, по сути это функция, которая принимает на вход аргументы - наши входные данные.  \n",
    "При инициализации она \"знает\" какую задачу ей необходимо решать, но пока что не умеет правильно это делать. Для этого ей необходимо понять и запомнить разные зависимости и закономерности во входных данных. Всю ту информацию, что она запоминает из входной выборки, она кодирует в свои же параметры, которых может быть огромное количество. Обучение модели как раз и заключается в поиске оптимальных значений параметров. Что значит оптимальность в данном случае рассмотрим ниже.\n",
    "\n",
    "Для понимания понятия оптимальности введем функцию потерь и стоимости.   \n",
    "Возьмем из нашей большой выборки (X,Y) один пример (x,y).\n",
    "Подадим наш х на вход модели М и получим ее ответ, назовем его z. Тип ответа модели не важен, это может быть скаляр, вектор, массив или какой-то другой тип данных, это никак не влиеяет на общую суть. Тепрь необходимо сформулировать в виде функции что будем считать хорошим ответом,а что плохим, это и будет нашей функцией потерь L.  То есть на вход она принимает ответ модели z и правильный ответ y и должна сосчитать на сколько они похожи/сходятся/соответствуют друг другу.   \n",
    "\n",
    "$M(x) = z$  \n",
    "$L(z,y) = loss\\_value$  \n",
    "$M(X) = Z = [z_1, z_2, ...,z_N]$  \n",
    "\n",
    "Теперь допустим мы пропустили всю нашу выборку через модель M, получили множество ответов Z. Посчитаем функцию потерь для каждого ответа: \n",
    "\n",
    "$L(Z,Y) = Loss\\_Values = [loss_1, loss_2, ..., loss_N]$\n",
    "\n",
    "Зададим следующую функцию как усреднение потерь по всей выборке:  \n",
    "\n",
    "$ С(M, X, Y) = \\frac{1}{N} * \\sum\\limits _{i=1}^{N} loss_i = \\frac{1}{N} * \\sum\\limits _{i=1}^{N} L(Z_i, Y_i) = \\frac{1}{N} * \\sum\\limits _{i=1}^{N} L(M(X_i), Y_i)$  \n",
    "\n",
    "**С(M, X, Y)** и будет нашей функцией стоимости. И так как по сути это стредняя ошибка алгоритма, цель обучения модели свести ее к минимуму.\n",
    "Еще такой момент, что здесь мы просто усредняли по выборке, но можно делать любую агрегацию - к примеру взвешенное усреднеение. Но как правило вес учитывается в функции потерь, а не стоимости.\n",
    "\n",
    "Смотрите. Во всех функциях что мы придумали, задали - M, L, C изменяемые параметры имеет только M, так как именно ее мы обучаем. Все остальное имеет конкртеный зафиксированный вид.\n",
    "\n",
    "Остается последний вопрос.  \n",
    "Вот мы придумали функцию потерь и функцию стоимости. Поняли какая средняя ошибка модели на выборке. Но как нам теперь обучать/оптимизировать модель? Для этого необходимо задать метод оптимизации, которой подбором оптимальный параметров модели M будет минимизаровать значение функции  **С** при заданных (X, Y).\n",
    "\n",
    "$С(M, X=fix, Y=fix)\\xrightarrow[\\textbf{Opt}]{\\text{}} min$  \n",
    "\n",
    "**Opt** - метод оптимизации, который позволяет подобрать оптимальные значения параметров модели М.\n",
    "Методы оптимизации это целый раздел математики, он не меньше чем сам ML. Поэтому ML в основном просто использует наработки из этой области.  \n",
    "**Важные замечания:**\n",
    "- Методы оптимизации как правило итеративные - мы шаг за шагом изменяем параметры и ищем их оптимальный набор, а не сразу находим точку минимума.\n",
    "- Так как функция стоимости является суммой слагаемых можно свести задачу к минимизации ее слагаемых. Подробнее в алгоритме обучения модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Алгоритм обучения модели\n",
    "Так как выборка очень большая (как правило), алгоритм обучения итеративный. Ниже описан примерный псевдокод/алгоритм.\n",
    "Еще\n",
    "```python\n",
    "for epoch in range(some_value):\n",
    "    shuffle(X,Y) # перемешиваем выбору, сохраняя соответствие x_i -> y_i\n",
    "    for x_batch, y_batch in (X,Y): # Достаем данные из выборки небольшими порциям = батчами\n",
    "        z_batch = M.predict(x_batch) # Делаем предсказания с помощью модели\n",
    "        losses = L(z_batch, y_batch) # Считаем потери на каждом примере из батча\n",
    "        params_updates = [] # Сюда будем записывать те изменения параметров модели, которые предлагает сделать шаг Оптимизации\n",
    "        for loss in losses: # Рассматриваем каждый лосс отдельно\n",
    "            udpates = Opt.minimize(loss) # Оптимизируем лосс, получаем дельту на которую необходимо изменить параметры Модели\n",
    "            params_updates.append(udpates) # Записываем их в список предложеных изменений параметров\n",
    "\n",
    "        params_updates = sum(params_updates) / len(params_updates) # Усредняем предложенные изменения\n",
    "        M.update_params(params_updates) # Изменяем параметры модели\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Цикл работы с моделями\n",
    "\n",
    "**1. Постановка задачи**\n",
    "\n",
    "Определяем, какую задачу мы решаем, например, классификация, кластеризация или регрессия.\n",
    "\n",
    "**2. Сбор и подготовка данных**\n",
    "\n",
    "Готовим данные:\n",
    "\n",
    "- в зависимости от метода приводим в нужный вид (категории в числа, если нужно)\n",
    "- нормализуем данные, приводим к нужной шкале\n",
    "- создаем свои признаки (например, переводим минуты в часы, добавляем на основе страны метку Россия / другие)\n",
    "- делим выборку или настраиваем кросс-валидацию\n",
    "\n",
    "**3. Выбираем модели и обучаем**\n",
    "\n",
    "- подбираем параметры модели, если есть такие\n",
    "- выбираем комбинации признаков, которые можно исопльзовать\n",
    "\n",
    "**4. Измеряем качество модели, выбираем лучшую**\n",
    "\n",
    "- оцениваем качество с помощью метрик\n",
    "- выбираем модель с наиболее высоким качеством\n",
    "- визуализируем резльутаты\n",
    "\n",
    "**6. Сохраняем модель и / или результаты**\n",
    "\n",
    "- сохраняем модель\n",
    "- сохраняем предсказания на тестовой выборке, если надо\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
